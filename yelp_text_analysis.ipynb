{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Read yelp.csv into a pandas DataFrame and examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-yxfBYGB6SEqszmxJxd97A</td>\n",
       "      <td>2007-12-13</td>\n",
       "      <td>m2CKSsepBCoRYWxiRUsxAg</td>\n",
       "      <td>4</td>\n",
       "      <td>Quiessence is, simply put, beautiful.  Full wi...</td>\n",
       "      <td>review</td>\n",
       "      <td>sqYN3lNgvPbPCTRsMFu27g</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zp713qNhx8d9KCJJnrw1xA</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>riFQ3vxNpP4rWLk_CSri2A</td>\n",
       "      <td>5</td>\n",
       "      <td>Drop what you're doing and drive here. After I...</td>\n",
       "      <td>review</td>\n",
       "      <td>wFweIWhv2fREZV_dYkz_1g</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hW0Ne_HTHEAgGF1rAdmR-g</td>\n",
       "      <td>2012-07-12</td>\n",
       "      <td>JL7GXJ9u4YMx7Rzs05NfiQ</td>\n",
       "      <td>4</td>\n",
       "      <td>Luckily, I didn't have to travel far to make m...</td>\n",
       "      <td>review</td>\n",
       "      <td>1ieuYcKS7zeAv_U15AB13A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wNUea3IXZWD63bbOQaOH-g</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>XtnfnYmnJYi71yIuGsXIUA</td>\n",
       "      <td>4</td>\n",
       "      <td>Definitely come for Happy hour! Prices are ama...</td>\n",
       "      <td>review</td>\n",
       "      <td>Vh_DlizgGhSqQh4qfZ2h6A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nMHhuYan8e3cONo3PornJA</td>\n",
       "      <td>2010-08-11</td>\n",
       "      <td>jJAIXA46pU1swYyRCdfXtQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Nobuo shows his unique talents with everything...</td>\n",
       "      <td>review</td>\n",
       "      <td>sUNkXg8-KFtCMQDV6zRzQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "5  -yxfBYGB6SEqszmxJxd97A  2007-12-13  m2CKSsepBCoRYWxiRUsxAg      4   \n",
       "6  zp713qNhx8d9KCJJnrw1xA  2010-02-12  riFQ3vxNpP4rWLk_CSri2A      5   \n",
       "7  hW0Ne_HTHEAgGF1rAdmR-g  2012-07-12  JL7GXJ9u4YMx7Rzs05NfiQ      4   \n",
       "8  wNUea3IXZWD63bbOQaOH-g  2012-08-17  XtnfnYmnJYi71yIuGsXIUA      4   \n",
       "9  nMHhuYan8e3cONo3PornJA  2010-08-11  jJAIXA46pU1swYyRCdfXtQ      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "5  Quiessence is, simply put, beautiful.  Full wi...  review   \n",
       "6  Drop what you're doing and drive here. After I...  review   \n",
       "7  Luckily, I didn't have to travel far to make m...  review   \n",
       "8  Definitely come for Happy hour! Prices are ama...  review   \n",
       "9  Nobuo shows his unique talents with everything...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  \n",
       "5  sqYN3lNgvPbPCTRsMFu27g     4       3      1  \n",
       "6  wFweIWhv2fREZV_dYkz_1g     7       7      4  \n",
       "7  1ieuYcKS7zeAv_U15AB13A     0       1      0  \n",
       "8  Vh_DlizgGhSqQh4qfZ2h6A     0       0      0  \n",
       "9  sUNkXg8-KFtCMQDV6zRzQg     0       1      0  "
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "yelp_dataset = pd.read_csv('data/yelp.csv')\n",
    "yelp_dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "Create a new DataFrame that only contains the 5-star and 1-star reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape (4086, 2)\n",
      "One Star reviews: 749\n",
      "Five Star reviews: 3337\n"
     ]
    }
   ],
   "source": [
    "col_names = ['stars', 'text']\n",
    "yelp_data = pd.read_csv('data/yelp.csv', usecols=col_names)\n",
    "yelp_data = yelp_data[yelp_data.stars.isin([1, 5])]\n",
    "print('Data Shape', yelp_data.shape)\n",
    "print('One Star reviews:', len(yelp_data[yelp_data.stars==1]))\n",
    "print('Five Star reviews:', len(yelp_data[yelp_data.stars==5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "Define X and y from the new DataFrame, and then split X and y into training and testing sets, using the review text as the only feature and the star rating as the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (2860,)\n",
      "X_test: (1226,)\n",
      "y_train: (2860,)\n",
      "y_test: (1226,)\n"
     ]
    }
   ],
   "source": [
    "X = yelp_data.text\n",
    "y = yelp_data.stars\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3)\n",
    "\n",
    "print('X_train:', X_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "Use CountVectorizer to create document-term matrices from X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2860, 16282)"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cvect = CountVectorizer()\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train_dtm = cvect.fit_transform(X_train)\n",
    "#X_train_dtm = tfidf.fit_transform(X_train)\n",
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1226, 16282)"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dtm = cvect.transform(X_test)\n",
    "#X_test_dtm = tfidf.transform(X_test)\n",
    "X_test_dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5\n",
    "Use multinomial Naive Bayes to predict the star rating for the reviews in the testing set, and then calculate the accuracy and print the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: 91\n",
      "Accuracy (Metrics): 0.9257748776508973\n",
      "Confusion Matrix: [[156  75]\n",
      " [ 16 979]]\n",
      "\n",
      "\n",
      "\n",
      "Accuracy (Matrix): 0.9257748776508973\n",
      "Misclassification: 0.07422512234910278\n",
      "Sensitivity (Predicting 5): 0.9839195979899498\n",
      "Precision (Predicting 5): 0.928842504743833\n",
      "Sensitivity (Predicting 1): 0.6753246753246753\n",
      "Precision (Predicting 1): 0.9069767441860465\n",
      "\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "1 Star Review       0.91      0.68      0.77       231\n",
      "5 Star Review       0.93      0.98      0.96       995\n",
      "\n",
      "  avg / total       0.92      0.93      0.92      1226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "mnb.fit(X_train_dtm, y_train)\n",
    "\n",
    "y_pred = mnb.predict(X_test_dtm)\n",
    "\n",
    "\n",
    "# Difference between test and predicted values\n",
    "print('Errors:', sum(y_test != y_pred))\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "# Accuracy\n",
    "print('Accuracy (Metrics):', metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:',conf_matrix)\n",
    "\n",
    "# Calculations\n",
    "# True Negative (The reveiws with [y_test = 1 and y_pred = 1])\n",
    "TN = conf_matrix[0,0] \n",
    "\n",
    "# False Positive (The reveiws with [y_test = 1 and y_pred = 5])\n",
    "FP = conf_matrix[0,1] \n",
    "\n",
    "# False Negative (The reveiws with [y_test = 5 and y_pred = 1])\n",
    "FN = conf_matrix[1,0] \n",
    "\n",
    "# True Positive (The reveiws with [y_test = 5 and y_pred = 5])\n",
    "TP = conf_matrix[1,1] \n",
    "\n",
    "Total = TN+FN+FP+TP\n",
    "\n",
    "# Accuracy\n",
    "print('\\n\\n')\n",
    "print('Accuracy (Matrix):', (TP+TN)/Total)\n",
    "\n",
    "# Misclassification\n",
    "print('Misclassification:', (FP+FN)/Total)\n",
    "\n",
    "# Sensitivity / Recall (How often model predicts star:5 when actually star:5)\n",
    "print('Sensitivity (Predicting 5):', TP/(TP+FN))\n",
    "\n",
    "# Precision (How many of predicted star:5 is actually star:5 OR how often it is correct when it predicts 5)\n",
    "print('Precision (Predicting 5):', TP/(TP+FP))\n",
    "\n",
    "# Sensitivity / Recall (How often model predicts star:1 when actually star:1)\n",
    "print('Sensitivity (Predicting 1):', TN/(TN+FP))\n",
    "\n",
    "# Precision (How many of predicted star:1 is actually star:1 OR how often it is correct when it predicts 1)\n",
    "if FN !=0:\n",
    "    print('Precision (Predicting 1):', TN/(TN+FN))\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['1 Star Review', '5 Star Review']\n",
    "print('\\n\\nClassification Report' )\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6 (Challenge)\n",
    "Calculate the null accuracy, which is the classification accuracy that could be achieved by always predicting the most frequent class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    995\n",
       "1    231\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null Accuracy: Examine the predicted class distribution of the testing set (using a Pandas Series method)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Accuracy: 0.8115823817292006\n"
     ]
    }
   ],
   "source": [
    "# Reviews with star 5 = 662 / Reviews with star 1 = 156 (5 is the most frequent class)\n",
    "\n",
    "# Calculate Mean\n",
    "y_test_mean_5 = y_test.value_counts().head(1)/len(y_test)\n",
    "y_test_mean_1 = 1 - y_test_mean_5\n",
    "\n",
    "print('Null Accuracy:', max(y_test_mean_1.item(), y_test_mean_5.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7 (Challenge)\n",
    "Browse through the review text of some of the false positives and false negatives. Based on your knowledge of how Naive Bayes works, do you have any ideas about why the model is incorrectly classifying these reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falsely Predicted as 5 (False Positive)\n",
      " 1527    The portions are too small, the plasticware ju...\n",
      "678     This store is banking on the hope they are the...\n",
      "3527    Wow! I can't believe this place gets so many g...\n",
      "1704    The only reason 1 star can be given is the fla...\n",
      "8617    Shocked this place has 4 stars. First off you ...\n",
      "8755    Not lesbian/gay friendly at all. I should have...\n",
      "9851    If you like sushi, go somewhere else. I was ex...\n",
      "3677    Hands down, the single worst public mass trans...\n",
      "436     this another place that i would give no stars ...\n",
      "7112    The staff is friendly. But the physical hotel ...\n",
      "Name: text, dtype: object\n",
      "\n",
      "Falsely Predicted as 1 (False Negative)\n",
      " 8053    My wife called to have our vent cleaned since ...\n",
      "3052    When I met some friends for dinner at this res...\n",
      "6321    Old school steak house.  Best 22oz ribeye I've...\n",
      "2494    What a great surprise stumbling across this ba...\n",
      "6050    I went to sears today to check on a layaway th...\n",
      "1266    I've never been to this location before. My hu...\n",
      "8404    Bruce saved my day, my computer crashed this m...\n",
      "672     Man, I love Southwest.  Best airline ever.  Af...\n",
      "354     We happened upon this location when meeting a ...\n",
      "4938    DUDE..where is the manga....where are the card...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Reviews that were (y_test=1 and y_pred=5) OR Reviews that were falsely predicted as 5 (Falsely predicted as Positive)\n",
    "print('Falsely Predicted as 5 (False Positive)\\n', X_test[y_test < y_pred].head(10))\n",
    "\n",
    "# Reviews that were (y_test=5 and y_pred=1) OR Reviews that were falsely predicted as 1 (Falsely predicted as Negative)\n",
    "print('\\nFalsely Predicted as 1 (False Negative)\\n', X_test[y_test > y_pred].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8 (Challenge)\n",
    "Calculate which 10 tokens are the most predictive of 5-star reviews, and which 10 tokens are the most predictive of 1-star reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bias Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '00am', '00pm', '01', '02', '04', '05', '06', '07', '09', '0l', '10', '100', '1000', '1001', '100s', '100th', '101', '1030', '1070', '108', '109', '10am', '10ish', '10min', '10minutes', '10pm', '10th', '10x', '10yo', '11', '110', '111', '111th', '112', '115', '116', '118', '11a', '11am', '11pm', '12', '120', '12am', '12oz', '12pm', '12th', '13', '1300']\n"
     ]
    }
   ],
   "source": [
    "# Print Feature Names\n",
    "feature_names = cvect.get_feature_names()\n",
    "print(feature_names[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29.,  4.,  1., ...,  0.,  0.,  0.],\n",
       "       [30.,  8.,  1., ...,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bias counts number of times feature appear in each class\n",
    "nb_feature_count = mnb.feature_count_\n",
    "nb_feature_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 16282)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rows represent classes, columns represent tokens\n",
    "mnb.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 518., 2342.])"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of observations in each class (First row is 1 star and Second row is 5 star)\n",
    "mnb.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30.,  8.,  1., ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of times each token appears for star 1 \n",
    "one_star_count =  nb_feature_count[1,:]\n",
    "one_star_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29.,  4.,  1., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of times each token appears for star 5 \n",
    "five_star_count = nb_feature_count[0,:]\n",
    "five_star_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Five_Star</th>\n",
       "      <th>One_Star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00am</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00pm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Feature  Five_Star  One_Star\n",
       "0      00       29.0      30.0\n",
       "1     000        4.0       8.0\n",
       "2    00am        1.0       1.0\n",
       "3    00pm        1.0       7.0\n",
       "4      01        1.0       0.0\n",
       "5      02        0.0       1.0\n",
       "6      04        0.0       1.0\n",
       "7      05        1.0       2.0\n",
       "8      06        0.0       2.0\n",
       "9      07        2.0       5.0"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame of tokens with their separate one-star and five-star counts\n",
    "tokens = pd.DataFrame({'Feature': feature_names, 'One_Star': one_star_count, 'Five_Star': five_star_count})\n",
    "tokens.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust values to avoid divide by zero\n",
    "\n",
    "add_one = lambda x : x+1\n",
    "tokens['Five_Star'] = tokens['Five_Star'].apply(add_one)\n",
    "tokens['One_Star'] = tokens['One_Star'].apply(add_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Five_Star</th>\n",
       "      <th>One_Star</th>\n",
       "      <th>One_Star_Freq</th>\n",
       "      <th>Five_Star_Freq</th>\n",
       "      <th>Fiveness</th>\n",
       "      <th>Oneness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6793</th>\n",
       "      <td>haunt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.884714</td>\n",
       "      <td>1.130309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15145</th>\n",
       "      <td>unappetizing</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.110589</td>\n",
       "      <td>9.042471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10444</th>\n",
       "      <td>pastas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>1.327071</td>\n",
       "      <td>0.753539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3578</th>\n",
       "      <td>cph</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.442357</td>\n",
       "      <td>2.260618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>bath</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>2.654142</td>\n",
       "      <td>0.376770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12405</th>\n",
       "      <td>salary</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.110589</td>\n",
       "      <td>9.042471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Feature  Five_Star  One_Star  One_Star_Freq  Five_Star_Freq  \\\n",
       "6793          haunt        1.0       4.0       0.001931        0.001708   \n",
       "15145  unappetizing        2.0       1.0       0.003861        0.000427   \n",
       "10444        pastas        1.0       6.0       0.001931        0.002562   \n",
       "3578            cph        1.0       2.0       0.001931        0.000854   \n",
       "1414           bath        1.0      12.0       0.001931        0.005124   \n",
       "12405        salary        2.0       1.0       0.003861        0.000427   \n",
       "\n",
       "       Fiveness   Oneness  \n",
       "6793   0.884714  1.130309  \n",
       "15145  0.110589  9.042471  \n",
       "10444  1.327071  0.753539  \n",
       "3578   0.442357  2.260618  \n",
       "1414   2.654142  0.376770  \n",
       "12405  0.110589  9.042471  "
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the one-star and five-star counts into frequencies\n",
    "tokens['One_Star_Freq'] = tokens.Five_Star/mnb.class_count_[0]\n",
    "tokens['Five_Star_Freq'] = tokens.One_Star/mnb.class_count_[1]\n",
    "tokens.sample(6, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out most predictive words\n",
    "tokens['Fiveness'] = tokens.Five_Star_Freq/tokens.One_Star_Freq\n",
    "tokens['Oneness'] = tokens.One_Star_Freq/tokens.Five_Star_Freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Five_Star</th>\n",
       "      <th>One_Star</th>\n",
       "      <th>One_Star_Freq</th>\n",
       "      <th>Five_Star_Freq</th>\n",
       "      <th>Fiveness</th>\n",
       "      <th>Oneness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5409</th>\n",
       "      <td>fantastic</td>\n",
       "      <td>2.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.080273</td>\n",
       "      <td>20.790777</td>\n",
       "      <td>0.048098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>awesome</td>\n",
       "      <td>3.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.005792</td>\n",
       "      <td>0.119983</td>\n",
       "      <td>20.717051</td>\n",
       "      <td>0.048269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10602</th>\n",
       "      <td>perfect</td>\n",
       "      <td>3.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.005792</td>\n",
       "      <td>0.099488</td>\n",
       "      <td>17.178195</td>\n",
       "      <td>0.058213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16209</th>\n",
       "      <td>yum</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.024338</td>\n",
       "      <td>12.607173</td>\n",
       "      <td>0.079320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5696</th>\n",
       "      <td>flavors</td>\n",
       "      <td>2.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.045260</td>\n",
       "      <td>11.722459</td>\n",
       "      <td>0.085306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11691</th>\n",
       "      <td>reasonably</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.017933</td>\n",
       "      <td>9.289496</td>\n",
       "      <td>0.107648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9451</th>\n",
       "      <td>mozzarella</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.017079</td>\n",
       "      <td>8.847139</td>\n",
       "      <td>0.113031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5450</th>\n",
       "      <td>favorite</td>\n",
       "      <td>8.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>0.015444</td>\n",
       "      <td>0.134500</td>\n",
       "      <td>8.708903</td>\n",
       "      <td>0.114825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8617</th>\n",
       "      <td>loved</td>\n",
       "      <td>4.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.066183</td>\n",
       "      <td>8.570666</td>\n",
       "      <td>0.116677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>brunch</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.016225</td>\n",
       "      <td>8.404782</td>\n",
       "      <td>0.118980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature  Five_Star  One_Star  One_Star_Freq  Five_Star_Freq  \\\n",
       "5409    fantastic        2.0     188.0       0.003861        0.080273   \n",
       "1215      awesome        3.0     281.0       0.005792        0.119983   \n",
       "10602     perfect        3.0     233.0       0.005792        0.099488   \n",
       "16209         yum        1.0      57.0       0.001931        0.024338   \n",
       "5696      flavors        2.0     106.0       0.003861        0.045260   \n",
       "11691  reasonably        1.0      42.0       0.001931        0.017933   \n",
       "9451   mozzarella        1.0      40.0       0.001931        0.017079   \n",
       "5450     favorite        8.0     315.0       0.015444        0.134500   \n",
       "8617        loved        4.0     155.0       0.007722        0.066183   \n",
       "2072       brunch        1.0      38.0       0.001931        0.016225   \n",
       "\n",
       "        Fiveness   Oneness  \n",
       "5409   20.790777  0.048098  \n",
       "1215   20.717051  0.048269  \n",
       "10602  17.178195  0.058213  \n",
       "16209  12.607173  0.079320  \n",
       "5696   11.722459  0.085306  \n",
       "11691   9.289496  0.107648  \n",
       "9451    8.847139  0.113031  \n",
       "5450    8.708903  0.114825  \n",
       "8617    8.570666  0.116677  \n",
       "2072    8.404782  0.118980  "
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words with high 'Fiveness'\n",
    "tokens.sort_values('Fiveness', ascending= False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Five_Star</th>\n",
       "      <th>One_Star</th>\n",
       "      <th>One_Star_Freq</th>\n",
       "      <th>Five_Star_Freq</th>\n",
       "      <th>Fiveness</th>\n",
       "      <th>Oneness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13672</th>\n",
       "      <td>staffperson</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.032819</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.013010</td>\n",
       "      <td>76.861004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11823</th>\n",
       "      <td>refused</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028958</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.014745</td>\n",
       "      <td>67.818533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>crappy</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.019305</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.022118</td>\n",
       "      <td>45.212355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7117</th>\n",
       "      <td>horrible</td>\n",
       "      <td>67.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.129344</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.023108</td>\n",
       "      <td>43.274683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10944</th>\n",
       "      <td>pointing</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017375</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.024575</td>\n",
       "      <td>40.691120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5585</th>\n",
       "      <td>filthy</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017375</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.024575</td>\n",
       "      <td>40.691120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15281</th>\n",
       "      <td>unprofessional</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015444</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.027647</td>\n",
       "      <td>36.169884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>fuse</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015444</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.027647</td>\n",
       "      <td>36.169884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5477</th>\n",
       "      <td>fedex</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015444</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.027647</td>\n",
       "      <td>36.169884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>acknowledged</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015444</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.027647</td>\n",
       "      <td>36.169884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature  Five_Star  One_Star  One_Star_Freq  Five_Star_Freq  \\\n",
       "13672     staffperson       17.0       1.0       0.032819        0.000427   \n",
       "11823         refused       15.0       1.0       0.028958        0.000427   \n",
       "3611           crappy       10.0       1.0       0.019305        0.000427   \n",
       "7117         horrible       67.0       7.0       0.129344        0.002989   \n",
       "10944        pointing        9.0       1.0       0.017375        0.000427   \n",
       "5585           filthy        9.0       1.0       0.017375        0.000427   \n",
       "15281  unprofessional        8.0       1.0       0.015444        0.000427   \n",
       "6080             fuse        8.0       1.0       0.015444        0.000427   \n",
       "5477            fedex        8.0       1.0       0.015444        0.000427   \n",
       "398      acknowledged        8.0       1.0       0.015444        0.000427   \n",
       "\n",
       "       Fiveness    Oneness  \n",
       "13672  0.013010  76.861004  \n",
       "11823  0.014745  67.818533  \n",
       "3611   0.022118  45.212355  \n",
       "7117   0.023108  43.274683  \n",
       "10944  0.024575  40.691120  \n",
       "5585   0.024575  40.691120  \n",
       "15281  0.027647  36.169884  \n",
       "6080   0.027647  36.169884  \n",
       "5477   0.027647  36.169884  \n",
       "398    0.027647  36.169884  "
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WOrds with high 'Oneness'\n",
    "tokens.sort_values('Oneness', ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
